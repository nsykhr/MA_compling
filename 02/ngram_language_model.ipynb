{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a class for our language model with an end-to-end pipeline inside of it: parsing the text file, text preprocessing, computing the frequency counts, creating the transition matrix, random text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import *\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "punctuation += '«»–—…“”'\n",
    "\n",
    "class NgramLanguageModel:\n",
    "    def __init__(self, path: str, n: int = 2) -> None:\n",
    "        if n < 2:\n",
    "            # Strictly speaking, it's possible, but I've decided not to deal with unigram language models here.\n",
    "            raise Exception('Parameter N of an n-gram language model cannot be less than 2!')\n",
    "        self.n = n\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "        self.sentences = map(lambda sentence: ['<START>'] * (self.n - 1) + \\\n",
    "                             [x for x in self.tokenize(sentence) if x] + ['<END>'],\n",
    "                             sent_tokenize(self.text))\n",
    "        self.token2id = {}\n",
    "        if self.n > 2:\n",
    "            self.ngram2id = {}\n",
    "        self.ngrams = [Counter(), Counter()]\n",
    "        self.get_ngram_counts()\n",
    "        self.vocab_size = len(self.token2id)\n",
    "        self.id2token = {value: key for key, value in self.token2id.items()}\n",
    "        self.matrix = np.zeros((len(self.ngrams[0]), self.vocab_size))\n",
    "        if self.n > 2:\n",
    "            self.id2ngram = {value: key for key, value in self.ngram2id.items()}\n",
    "        self.populate_matrix()\n",
    "    \n",
    "    def get_ngram_counts(self) -> None:\n",
    "        if self.n == 2:\n",
    "            for sentence in self.sentences:\n",
    "                self.ngrams[0].update(sentence)\n",
    "                self.ngrams[1].update(list(self.ngrammer(sentence, 2)))\n",
    "                self.update_token2id(sentence)\n",
    "        if self.n > 2:\n",
    "            for sentence in self.sentences:\n",
    "                ngrams = list(self.ngrammer(sentence, self.n-1))\n",
    "                self.ngrams[0].update(ngrams)\n",
    "                self.ngrams[1].update(list(self.ngrammer(sentence, self.n)))\n",
    "                self.update_token2id(sentence)\n",
    "                self.update_ngram2id(ngrams)\n",
    "    \n",
    "    def update_token2id(self, tokens: List[str]) -> None:\n",
    "        for token in tokens:\n",
    "            if token not in self.token2id:\n",
    "                self.token2id[token] = len(self.token2id)\n",
    "    \n",
    "    def update_ngram2id(self, ngrams: List[str]) -> None:\n",
    "        for ngram in ngrams:\n",
    "            if ngram not in self.ngram2id:\n",
    "                self.ngram2id[ngram] = len(self.ngram2id)\n",
    "    \n",
    "    def populate_matrix(self):\n",
    "        if self.n == 2:\n",
    "            for ngram, count in self.ngrams[1].items():\n",
    "                src, dest = ngram.split()\n",
    "                self.matrix[self.token2id[src], self.token2id[dest]] = \\\n",
    "                    count / self.ngrams[0][src]\n",
    "        if self.n > 2:\n",
    "            for ngram, count in self.ngrams[1].items():\n",
    "                ngram_splitted = ngram.split()\n",
    "                src = ' '.join(ngram_splitted[:-1])\n",
    "                dest = ngram_splitted[-1]\n",
    "                self.matrix[self.ngram2id[src], self.token2id[dest]] = \\\n",
    "                    count / self.ngrams[0][src]\n",
    "\n",
    "    def generate_random_text(self, n: int = 100,\n",
    "                             random_state: int = None) -> Generator[str, None, None]:\n",
    "        if self.n == 2:\n",
    "            current_idx = self.token2id['<START>']\n",
    "            for i in range(n):\n",
    "                if random_state:\n",
    "                    np.random.seed(random_state)\n",
    "                chosen = np.random.choice(self.vocab_size, p=self.matrix[current_idx])\n",
    "                yield self.id2token[chosen]\n",
    "                if chosen == self.token2id['<END>']:\n",
    "                    chosen = self.token2id['<START>']\n",
    "                current_idx = chosen\n",
    "        if self.n > 2:\n",
    "            current_idx = self.ngram2id[' '.join(['<START>'] * (self.n-1))]\n",
    "            for i in range(n):\n",
    "                if random_state:\n",
    "                    np.random.seed(random_state)\n",
    "                chosen = np.random.choice(self.vocab_size, p=self.matrix[current_idx])\n",
    "                yield self.id2token[chosen]\n",
    "                if chosen == self.token2id['<END>']:\n",
    "                    current_idx = self.ngram2id[' '.join(['<START>'] * (self.n-1))]\n",
    "                else:\n",
    "                    current_idx = self.ngram2id[' '.join(self.id2ngram[current_idx].split()[1:] +\n",
    "                                                         [self.id2token[chosen]])]\n",
    "            \n",
    "    @staticmethod\n",
    "    def tokenize(sentence: str) -> map:\n",
    "        return map(lambda x: x.strip(punctuation).replace('ё', 'е'),\n",
    "                   sentence.strip().lower().split())\n",
    "    \n",
    "    @staticmethod\n",
    "    def ngrammer(sentence: List[str], n: int) -> Generator[str, None, None]:\n",
    "        for i in range(len(sentence)-n+1):\n",
    "            yield ' '.join(sentence[i: i+n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolstoy2 = NgramLanguageModel('anna_karenina.txt', 2)\n",
    "dostoevsky2 = NgramLanguageModel('besy_dostoevsky.txt', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и пожить там сиял своею внешностью продолжал он скажет кити и старался левин уже уехали \n",
      " приезжайте вечером ни наука на пюпитре требуют от развода при ней при каждом его василий лукич был намерен был совершенно доволен своею внешностью поддерживал всякий согласится что последняя канавка с теми мыслями о прекрасно \n",
      " ты не нравилось \n",
      " если натура слишком оживленный с полным ртом поднял красно-пегого теленка на веселую какою она покраснела и не думаю что я считаю его шаги \n",
      " а брал все приготовил это \n",
      " старуха укутывала ноги рыжего направо кто был влюблен в назначенный день \n",
      " взойдя наверх чтобы\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([x for x in tolstoy2.generate_random_text()]).replace('<END>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ей сами это от ури не отвечаете \n",
      " у нас \n",
      " теперь \n",
      " если правда все больше врагов я ухожу не помня себя свою круглую совсем вон у a sonn&#233 \n",
      " эта блондинка с оглавлениями указаниями с визитом \n",
      " да что ее обнял страх пред вами с ничем и ангел она принуждена петь с обильно заваренным чаем \n",
      " лет семь человек \n",
      " николай всеволодович слушал сдвинув брови были тщеславны до колена в спасов \n",
      " именно пробормотал кириллов объявляю наш русский атеизм никогда прежде и отпер все страшно \n",
      " за что ничего а в зеркало \n",
      " вы только которые посетитель подымался\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([x for x in dostoevsky2.generate_random_text()]).replace('<END>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolstoy3 = NgramLanguageModel('anna_karenina.txt', 3)\n",
    "dostoevsky3 = NgramLanguageModel('besy_dostoevsky.txt', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "она знала шел к ней эта атмосфера забот которою он любовался на эту тему прекратился \n",
      " она не поднялась и оттолкнула его от этого выйти что она беременна \n",
      " эти точно такие же и на восторженные ее уверения в нежности его теперь она была а была долли с вронским совсем конченным что оно было вне того круга в котором теперь чувствовала себя виноватою \n",
      " забыл все то что увязили его лошадей и когда пошел искать убитого то не следует а то этак можно самому привыкнуть и ее закопают и федора подавальщика с его красотой милою улыбкой и держась своей первой\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([x for x in tolstoy3.generate_random_text()]).replace('<END>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гм \n",
      " мучь меня казни меня срывай на мне злобу вскричал он с чрезвычайным замешательством и краснея как только можно вообразить себе \n",
      " 258 я совсем другое дело настоящий пожар тут ужас и все я думаю даже что он вовсе не выходить а сейчас же объясниться \n",
      " сплетник \n",
      " но ведь тогда что они не обращали на него \n",
      " наконец разместились утихла и музыка \n",
      " ведь он знает это заранее все равно \n",
      " вдруг и брякнет мне главный вопрос который вас интересует пробормотал ставрогин \n",
      " вы атеист потому что ставрогин не может вы кликните \n",
      " в последние минуты не все\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([x for x in dostoevsky3.generate_random_text()]).replace('<END>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions of a trigram language model better resemble a coherent text. Perhaps, if we keep increasing the n-gram size, the quality of the generated text will keep growing, but the problem of training corpus size will keep growing as well. The longer the context we want to consider is, the more data we need. Besides, the computed frequency counts have to be smoothed in some tricky ways for a less predetermined output, but this is outside the scope of this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
