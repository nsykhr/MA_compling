{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import string\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's augment the stopword set with some Python syntax, numbers, two types of a long dash, and some random stopwords.\n",
    "stops = set(stopwords.words('russian')) | {'gt', 'from', 'import', 'and', 'or', 'is', 'in',\n",
    "                                           'if', 'for', 'while', 'none', 'null', 'return', 'yield',\n",
    "                                           'break', 'pass', 'continue', 'int'} | \\\n",
    "                                            set(map(str, range(10))) | \\\n",
    "                                            {'–', '—', 'очень', 'n', 'a', 'x'}\n",
    "\n",
    "def remove_tags(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "def opt_normalize(texts, top=50000):\n",
    "    unique = Counter()\n",
    "    for text in texts:\n",
    "        unique.update(text)\n",
    "    \n",
    "    norm_unique = {word: morph.parse(word)[0].normal_form for word, _ in unique.most_common(top)}\n",
    "    \n",
    "    norm_texts = []\n",
    "    for text in texts:\n",
    "        norm_words = [norm_unique.get(word) for word in text]\n",
    "        norm_words = [word for word in norm_words if word and word not in stops]\n",
    "        norm_texts.append(norm_words)\n",
    "        \n",
    "    return norm_texts\n",
    "\n",
    "def tokenize(text):\n",
    "    # For tokenization let's use the word_tokenize function from nltk.\n",
    "    words = [word.strip(string.punctuation) for word in word_tokenize(text)]\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('habr_texts.txt').read().splitlines()\n",
    "texts = opt_normalize([tokenize(remove_tags(text.lower())) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masstransit',\n",
       " 'это',\n",
       " 'open',\n",
       " 'source',\n",
       " 'библиотека',\n",
       " 'разработать',\n",
       " 'язык',\n",
       " 'c',\n",
       " 'net',\n",
       " 'платформа',\n",
       " 'работа',\n",
       " 'шина',\n",
       " 'дать',\n",
       " 'который',\n",
       " 'использоваться',\n",
       " 'построение',\n",
       " 'распределенный',\n",
       " 'приложение',\n",
       " 'реализация',\n",
       " 'soa',\n",
       " 'service',\n",
       " 'oriented',\n",
       " 'architecture',\n",
       " 'качество',\n",
       " 'message']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.3)\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masstransit',\n",
       " 'это',\n",
       " 'open_source',\n",
       " 'библиотека',\n",
       " 'разработать',\n",
       " 'язык_c',\n",
       " 'net',\n",
       " 'платформа',\n",
       " 'работа',\n",
       " 'шина',\n",
       " 'дать',\n",
       " 'который',\n",
       " 'использоваться',\n",
       " 'построение_распределенный',\n",
       " 'приложение',\n",
       " 'реализация',\n",
       " 'soa',\n",
       " 'service',\n",
       " 'oriented',\n",
       " 'architecture',\n",
       " 'качество',\n",
       " 'message',\n",
       " 'мочь',\n",
       " 'выступать',\n",
       " 'rabbitmq']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammed_texts[0][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some meaningful n-grams have emerged: \"open\\_source\", \"язык\\_C\", \"построение\\_распределенный\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
    "\n",
    "# Let's filter out frequent words a little less strictly.\n",
    "dictionary.filter_extremes(no_above=0.5, no_below=20)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure we have deleted the stopwords.\n",
    "\n",
    "assert all(stop not in dictionary.token2id for stop in stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9726 unique tokens: ['2-х', '3.0', 'address', 'api', 'architecture']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, num_topics=100, id2word=dictionary, passes=10)\n",
    "topics = lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model leaves much to be desired: only a few topics are actually interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " '0.038*\"сервер\" + 0.029*\"т.е\" + 0.017*\"какой-то\" + 0.016*\"запрос\" + 0.012*\"делать\" + 0.009*\"очередь\" + 0.009*\"клиент\" + 0.008*\"либо\" + 0.007*\"ответ\" + 0.006*\"пользователь\"')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Servers.\n",
    "\n",
    "topics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " '0.022*\"человек\" + 0.009*\"год\" + 0.005*\"мозг\" + 0.005*\"исследование\" + 0.005*\"учёный\" + 0.005*\"пациент\" + 0.004*\"говорить\" + 0.004*\"результат\" + 0.004*\"«_»\" + 0.004*\"жизнь\"')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cognitive science.\n",
    "\n",
    "topics[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,\n",
       " '0.011*\"книга\" + 0.010*\"программа\" + 0.009*\"человек\" + 0.009*\"курс\" + 0.007*\"делать\" + 0.007*\"компьютер\" + 0.006*\"программирование\" + 0.006*\"написать\" + 0.006*\"читать\" + 0.006*\"писать\"')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Programming courses?\n",
    "\n",
    "topics[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,\n",
       " '0.012*\"алгоритм\" + 0.012*\"изображение\" + 0.012*\"модель\" + 0.009*\"сеть\" + 0.009*\"обучение\" + 0.008*\"результат\" + 0.008*\"метод\" + 0.007*\"задача\" + 0.007*\"нейросеть\" + 0.006*\"значение\"')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine learning?\n",
    "\n",
    "topics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.234579989955254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.log_perplexity(corpus[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(dictionary=dictionary)\n",
    "tfidf_corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lda = gensim.models.LdaMulticore(tfidf_corpus, num_topics=100, id2word=dictionary, passes=25)\n",
    "tfidf_topics = tfidf_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.83737942599991"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lda.log_perplexity(tfidf_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,\n",
       " '0.067*\"lt_div\" + 0.044*\"let\" + 0.023*\"func\" + 0.019*\"def\" + 0.019*\"jsx\" + 0.017*\"react\" + 0.017*\"nil\" + 0.016*\"do\" + 0.016*\"sql_server\" + 0.014*\"view\"')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just random english words :)\n",
    "\n",
    "tfidf_topics[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76,\n",
       " '0.058*\"css\" + 0.043*\"react\" + 0.042*\"angular\" + 0.031*\"javascript\" + 0.024*\"роскомнадзор\" + 0.017*\"материя\" + 0.013*\"тёмный_материя\" + 0.012*\"redux\" + 0.011*\"svg\" + 0.007*\"переговоры\"')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frontend + space + some noise.\n",
    "\n",
    "tfidf_topics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87,\n",
       " '0.041*\"марс\" + 0.031*\"миссия\" + 0.030*\"зонд\" + 0.023*\"планета\" + 0.022*\"аппарат\" + 0.017*\"автопилот\" + 0.016*\"земля\" + 0.013*\"посадка\" + 0.013*\"paypal\" + 0.012*\"солнечный\"')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Space + some noise.\n",
    "\n",
    "tfidf_topics[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in perplexion is in accordance with the overall feeling left after looking at the topics: they became even worse. In many cases a mix of several topics in one is evident, and in all the topics there is noise.\n",
    "\n",
    "It's difficult to compare individual topics because for that one needs to establish an alignment between two sets of 100 topics — and this alignment probably doesn't exist.\n",
    "\n",
    "During the preparation of this notebook I tried several different numbers of collection passes, and it appears that perplexion doesn't necessarily decrease with the increase of this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stexts = [' '.join(text) for text in ngrammed_texts]\n",
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=40, max_df=0.5, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=20)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['делать', 'какой', 'что', 'какой то', 'ваш', 'книга', 'человек', 'что то', 'хотеть', 'знать']\n",
      "2 ['функция', 'код', 'объект', 'значение', 'метод', 'класс', 'тип', 'алгоритм', 'строка', 'элемент']\n",
      "3 ['игра', 'игрок', 'игровой', 'играть', 'разработчик', 'уровень', 'разработка', 'мир', 'карта', 'экран']\n",
      "4 ['приложение', 'пользователь', 'android', 'разработчик', 'мобильный', 'разработка', 'сервис', 'api', 'google', 'платформа']\n",
      "5 ['устройство', 'смартфон', 'датчик', 'функция', 'атака', 'производитель', 'безопасность', 'android', 'защита', 'драйвер']\n",
      "6 ['сервер', 'клиент', 'запрос', 'сервис', 'дата центр', 'дата', 'центр', 'база_дать', 'облако', 'инфраструктура']\n",
      "7 ['компания', 'сотрудник', 'год', 'рынок', 'бизнес', 'клиент', 'google', 'российский', 'microsoft', 'продажа']\n",
      "8 ['камера', 'смартфон', 'звук', 'цена', 'экран', 'видео', 'модель', 'телефон', 'корпус', 'процессор']\n",
      "9 ['файл', 'скрипт', 'настройка', 'пакет', 'папка', 'команда', 'строка', 'добавить', 'репозиторий', 'установка']\n",
      "10 ['человек', 'мозг', 'пациент', 'исследование', 'учёный', 'год', 'жизнь', 'исследователь', 'ребёнок', 'результат']\n",
      "11 ['сайт', 'пользователь', 'страница', 'браузер', 'реклама', 'контент', 'информация', 'домен', 'веб', 'адрес']\n",
      "12 ['год', 'вселенная', 'земля', 'энергия', 'учёный', 'температура', 'аппарат', 'центр', 'поверхность', 'сигнал']\n",
      "13 ['lt', 'lt_lt', 'amp', 'name', 'amp_amp', 'void', 'string', 'else', 'new', 'data']\n",
      "14 ['проект', 'команда', 'разработчик', 'разработка', 'задача', 'код', 'продукт', 'программа', 'создание', 'инструмент']\n",
      "15 ['var', 'this', 'lt_div', 'function', 'id', 'string', 'class', 'new', 'the', 'const']\n",
      "16 ['печать', '3d', 'материал', 'модель', 'робот', 'производство', 'деталь', 'технология', 'слой', 'автомобиль']\n",
      "17 ['доклад', 'конференция', 'участник', 'разработчик', 'тема', 'рассказать', '00', 'java', 'год', 'разработка']\n",
      "18 ['сеть', 'трафик', 'сигнал', 'связь', 'интернет', 'пакет', 'атака', 'адрес', 'протокол', 'канал']\n",
      "19 ['система', 'решение', 'пользователь', 'процесс', 'задача', 'безопасность', 'управление', 'использование', 'тест', 'процессор']\n",
      "20 ['бот', 'сообщение', 'пользователь', 'сервис', 'канал', 'команда', 'api', 'робот', 'игрок', 'google']\n"
     ]
    }
   ],
   "source": [
    "feat_names = vectorizer.get_feature_names()\n",
    "top_words = model.components_.argsort()[:, :-11:-1]\n",
    "\n",
    "for i in range(top_words.shape[0]):\n",
    "    words = [feat_names[j] for j in top_words[i]]\n",
    "    print(i+1, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the topics seem nice and interpretable.\n",
    "Only topics 1, 13, 15, and 20 are somewhat less clear. Besides, some of the topics intersect.\n",
    "\n",
    "1: ?philosophy and literature\n",
    "2: OOP\n",
    "3: game development\n",
    "4: web-development\n",
    "5: gadgets\n",
    "6: data infrastructure\n",
    "7: IT business news\n",
    "8: gadgets again\n",
    "9: files, scripts, repositories\n",
    "10: cognitive science\n",
    "11: web\n",
    "12: space\n",
    "13: some programming languages\n",
    "14: management in IT\n",
    "15: some programming languages again\n",
    "16: manufacturing technologies\n",
    "17: papers and conferences\n",
    "18: net\n",
    "19: systems\n",
    "20: ?frontend, web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA with 20 topics (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, num_topics=20, id2word=dictionary, passes=10)\n",
    "topics = lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['человек', 'компания', 'год', 'делать', 'проект', 'говорить', 'деньга', 'сотрудник', 'хотеть']\n",
      "2 ['lt', 'name', 'string', 'the', 'i', 'this', 'amp', 'файл', 'type']\n",
      "3 ['запрос', 'сервер', 'система', 'диск', 'пользователь', 'проблема', 'тест', 'запись']\n",
      "4 ['код', 'класс', 'объект', 'метод', 'файл', 'элемент', 'тип', 'функция', 'приложение', 'пример']\n",
      "5 ['человек', 'год', 'компания', 'робот', 'система', 'машина', 'технология', 'автомобиль', 'ия', 'компьютер']\n",
      "6 ['звук', 'человек', 'глаз', 'учёный', 'движение', 'тело', 'пациент', 'случай', 'система']\n",
      "7 ['проект', 'задача', 'разработка', 'разработчик', 'сайт', 'делать', 'продукт', 'игра', 'команда', 'язык']\n",
      "8 ['человек', 'год', 'ребёнок', 'ваш', 'исследование', 'мозг', 'курс', 'результат']\n",
      "9 ['точка', 'объект', 'значение', 'алгоритм', 'вселенная', 'тип', 'число', 'результат', 'количество', 'координата']\n",
      "10 ['игра', 'игрок', 'игровой', 'играть', 'процессор', 'сервер', 'система', 'уровень', 'видеокарта']\n",
      "11 ['компания', 'пользователь', 'сервис', 'клиент', 'система', 'информация', 'сайт', 'год', 'решение', 'рынок']\n",
      "12 ['год', 'система', 'земля', 'спутник', 'проект', 'аппарат', 'звезда', 'станция', 'энергия']\n",
      "13 ['функция', 'код', 'значение', 'память', 'программа', 'число', 'тип', 'массив', 'результат']\n",
      "14 ['делать', 'написать', 'писать', 'язык', 'слово', 'человек', 'доклад', 'код']\n",
      "15 ['запись', 'транзакция', 'элемент', 'список', 'запрос', 'модель', 'блок']\n",
      "16 ['приложение', 'файл', 'проект', 'устройство', 'команда', 'система', 'версия', 'необходимый', 'пакет', 'помощь']\n",
      "17 ['сеть', 'система', 'модель', 'сигнал', 'изображение', 'задача', 'результат', 'решение', 'устройство', 'являться']\n",
      "18 ['сервер', 'клиент', 'настройка', 'пользователь', 'адрес', 'сеть', 'домен', 'сайт', 'система', 'ваш']\n",
      "19 ['пользователь', 'приложение', 'устройство', 'система', 'пароль', 'уязвимость', 'безопасность', 'атака', 'информация', 'android']\n",
      "20 ['устройство', 'камера', 'модель', 'смартфон', 'компания', 'цена', 'год', 'экран', 'телефон']\n"
     ]
    }
   ],
   "source": [
    "for i, topic in topics:\n",
    "    print(i+1, re.findall(r'(?<=\")[A-Za-zА-Яа-яЁё]+(?=\")', topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's evident that almost all of the topics are noisy or outright uninterpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
