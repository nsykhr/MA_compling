{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import string\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним словарь стоп-слов синтаксисом Python, цифрами, двумя тире, рандомными словами.\n",
    "stops = set(stopwords.words('russian')) | {'gt', 'from', 'import', 'and', 'or', 'is', 'in',\n",
    "                                           'if', 'for', 'while', 'none', 'null', 'return', 'yield',\n",
    "                                           'break', 'pass', 'continue', 'int'} | \\\n",
    "                                            set(map(str, range(10))) | \\\n",
    "                                            {'–', '—', 'очень', 'n', 'a', 'x'}\n",
    "\n",
    "def remove_tags(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "def opt_normalize(texts, top=50000):\n",
    "    unique = Counter()\n",
    "    for text in texts:\n",
    "        unique.update(text)\n",
    "    \n",
    "    norm_unique = {word: morph.parse(word)[0].normal_form for word, _ in unique.most_common(top)}\n",
    "    \n",
    "    norm_texts = []\n",
    "    for text in texts:\n",
    "        norm_words = [norm_unique.get(word) for word in text]\n",
    "        norm_words = [word for word in norm_words if word and word not in stops]\n",
    "        norm_texts.append(norm_words)\n",
    "        \n",
    "    return norm_texts\n",
    "\n",
    "def tokenize(text):\n",
    "    # Для токенизации используем word_tokenize из nltk.\n",
    "    words = [word.strip(string.punctuation) for word in word_tokenize(text)]\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('habr_texts.txt').read().splitlines()\n",
    "texts = opt_normalize([tokenize(remove_tags(text.lower())) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masstransit',\n",
       " 'это',\n",
       " 'open',\n",
       " 'source',\n",
       " 'библиотека',\n",
       " 'разработать',\n",
       " 'язык',\n",
       " 'c',\n",
       " 'net',\n",
       " 'платформа',\n",
       " 'работа',\n",
       " 'шина',\n",
       " 'дать',\n",
       " 'который',\n",
       " 'использоваться',\n",
       " 'построение',\n",
       " 'распределенный',\n",
       " 'приложение',\n",
       " 'реализация',\n",
       " 'soa',\n",
       " 'service',\n",
       " 'oriented',\n",
       " 'architecture',\n",
       " 'качество',\n",
       " 'message']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Энграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.3)\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masstransit',\n",
       " 'это',\n",
       " 'open_source',\n",
       " 'библиотека',\n",
       " 'разработать',\n",
       " 'язык_c',\n",
       " 'net',\n",
       " 'платформа',\n",
       " 'работа',\n",
       " 'шина',\n",
       " 'дать',\n",
       " 'который',\n",
       " 'использоваться',\n",
       " 'построение_распределенный',\n",
       " 'приложение',\n",
       " 'реализация',\n",
       " 'soa',\n",
       " 'service',\n",
       " 'oriented',\n",
       " 'architecture',\n",
       " 'качество',\n",
       " 'message',\n",
       " 'мочь',\n",
       " 'выступать',\n",
       " 'rabbitmq']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammed_texts[0][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появились осмысленные энграммы: \"open\\_source\", \"язык\\_C\", \"построение\\_распределенный\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
    "\n",
    "# Будем не так строго фильтровать частые слова.\n",
    "dictionary.filter_extremes(no_above=0.5, no_below=20)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы отфильтровали стоп-слова.\n",
    "\n",
    "assert all(stop not in dictionary.token2id for stop in stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9726 unique tokens: ['2-х', '3.0', 'address', 'api', 'architecture']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, num_topics=100, id2word=dictionary, passes=10)\n",
    "topics = lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученная модель оставляет желать лучшего: только некоторые темы хорошо интерпретируемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " '0.038*\"сервер\" + 0.029*\"т.е\" + 0.017*\"какой-то\" + 0.016*\"запрос\" + 0.012*\"делать\" + 0.009*\"очередь\" + 0.009*\"клиент\" + 0.008*\"либо\" + 0.007*\"ответ\" + 0.006*\"пользователь\"')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Серверы.\n",
    "\n",
    "topics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " '0.022*\"человек\" + 0.009*\"год\" + 0.005*\"мозг\" + 0.005*\"исследование\" + 0.005*\"учёный\" + 0.005*\"пациент\" + 0.004*\"говорить\" + 0.004*\"результат\" + 0.004*\"«_»\" + 0.004*\"жизнь\"')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Когнитивные исследования.\n",
    "\n",
    "topics[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,\n",
       " '0.011*\"книга\" + 0.010*\"программа\" + 0.009*\"человек\" + 0.009*\"курс\" + 0.007*\"делать\" + 0.007*\"компьютер\" + 0.006*\"программирование\" + 0.006*\"написать\" + 0.006*\"читать\" + 0.006*\"писать\"')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Курсы по программированию?\n",
    "\n",
    "topics[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,\n",
       " '0.012*\"алгоритм\" + 0.012*\"изображение\" + 0.012*\"модель\" + 0.009*\"сеть\" + 0.009*\"обучение\" + 0.008*\"результат\" + 0.008*\"метод\" + 0.007*\"задача\" + 0.007*\"нейросеть\" + 0.006*\"значение\"')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Машинное обучение?\n",
    "\n",
    "topics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.234579989955254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.log_perplexity(corpus[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(dictionary=dictionary)\n",
    "tfidf_corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lda = gensim.models.LdaMulticore(tfidf_corpus, num_topics=100, id2word=dictionary, passes=25)\n",
    "tfidf_topics = tfidf_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28.83737942599991"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lda.log_perplexity(tfidf_corpus[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,\n",
       " '0.067*\"lt_div\" + 0.044*\"let\" + 0.023*\"func\" + 0.019*\"def\" + 0.019*\"jsx\" + 0.017*\"react\" + 0.017*\"nil\" + 0.016*\"do\" + 0.016*\"sql_server\" + 0.014*\"view\"')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просто все подряд слова на английском :)\n",
    "\n",
    "tfidf_topics[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76,\n",
       " '0.058*\"css\" + 0.043*\"react\" + 0.042*\"angular\" + 0.031*\"javascript\" + 0.024*\"роскомнадзор\" + 0.017*\"материя\" + 0.013*\"тёмный_материя\" + 0.012*\"redux\" + 0.011*\"svg\" + 0.007*\"переговоры\"')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Фронтенд + космос + разный мусор.\n",
    "\n",
    "tfidf_topics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87,\n",
       " '0.041*\"марс\" + 0.031*\"миссия\" + 0.030*\"зонд\" + 0.023*\"планета\" + 0.022*\"аппарат\" + 0.017*\"автопилот\" + 0.016*\"земля\" + 0.013*\"посадка\" + 0.013*\"paypal\" + 0.012*\"солнечный\"')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Космос + разный мусор.\n",
    "\n",
    "tfidf_topics[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение значения перплексии по модулю согласуется с визуальным ощущением от просмотра тем: они стали ещё хуже. Во многих случаях очевидно смешение нескольких тем в одной, во всех темах есть мусор.\n",
    "\n",
    "Сравнивать темы по отдельности трудно, поскольку для этого нужно установить \"выравнивание\" между двумя наборами по 100 тем, а главное, этого выравнивания, скорее всего, и нет.\n",
    "\n",
    "В процессе работы я попробовал разные значения количества проходов по коллекции и обратил внимание, что с его увеличением перплексия не обязательно падает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stexts = [' '.join(text) for text in ngrammed_texts]\n",
    "vectorizer = TfidfVectorizer(max_features=1000, min_df=40, max_df=0.5, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NMF(n_components=20)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['делать', 'какой', 'что', 'какой то', 'ваш', 'книга', 'человек', 'что то', 'хотеть', 'знать']\n",
      "2 ['функция', 'код', 'объект', 'значение', 'метод', 'класс', 'тип', 'алгоритм', 'строка', 'элемент']\n",
      "3 ['игра', 'игрок', 'игровой', 'играть', 'разработчик', 'уровень', 'разработка', 'мир', 'карта', 'экран']\n",
      "4 ['приложение', 'пользователь', 'android', 'разработчик', 'мобильный', 'разработка', 'сервис', 'api', 'google', 'платформа']\n",
      "5 ['устройство', 'смартфон', 'датчик', 'функция', 'атака', 'производитель', 'безопасность', 'android', 'защита', 'драйвер']\n",
      "6 ['сервер', 'клиент', 'запрос', 'сервис', 'дата центр', 'дата', 'центр', 'база_дать', 'облако', 'инфраструктура']\n",
      "7 ['компания', 'сотрудник', 'год', 'рынок', 'бизнес', 'клиент', 'google', 'российский', 'microsoft', 'продажа']\n",
      "8 ['камера', 'смартфон', 'звук', 'цена', 'экран', 'видео', 'модель', 'телефон', 'корпус', 'процессор']\n",
      "9 ['файл', 'скрипт', 'настройка', 'пакет', 'папка', 'команда', 'строка', 'добавить', 'репозиторий', 'установка']\n",
      "10 ['человек', 'мозг', 'пациент', 'исследование', 'учёный', 'год', 'жизнь', 'исследователь', 'ребёнок', 'результат']\n",
      "11 ['сайт', 'пользователь', 'страница', 'браузер', 'реклама', 'контент', 'информация', 'домен', 'веб', 'адрес']\n",
      "12 ['год', 'вселенная', 'земля', 'энергия', 'учёный', 'температура', 'аппарат', 'центр', 'поверхность', 'сигнал']\n",
      "13 ['lt', 'lt_lt', 'amp', 'name', 'amp_amp', 'void', 'string', 'else', 'new', 'data']\n",
      "14 ['проект', 'команда', 'разработчик', 'разработка', 'задача', 'код', 'продукт', 'программа', 'создание', 'инструмент']\n",
      "15 ['var', 'this', 'lt_div', 'function', 'id', 'string', 'class', 'new', 'the', 'const']\n",
      "16 ['печать', '3d', 'материал', 'модель', 'робот', 'производство', 'деталь', 'технология', 'слой', 'автомобиль']\n",
      "17 ['доклад', 'конференция', 'участник', 'разработчик', 'тема', 'рассказать', '00', 'java', 'год', 'разработка']\n",
      "18 ['сеть', 'трафик', 'сигнал', 'связь', 'интернет', 'пакет', 'атака', 'адрес', 'протокол', 'канал']\n",
      "19 ['система', 'решение', 'пользователь', 'процесс', 'задача', 'безопасность', 'управление', 'использование', 'тест', 'процессор']\n",
      "20 ['бот', 'сообщение', 'пользователь', 'сервис', 'канал', 'команда', 'api', 'робот', 'игрок', 'google']\n"
     ]
    }
   ],
   "source": [
    "feat_names = vectorizer.get_feature_names()\n",
    "top_words = model.components_.argsort()[:, :-11:-1]\n",
    "\n",
    "for i in range(top_words.shape[0]):\n",
    "    words = [feat_names[j] for j in top_words[i]]\n",
    "    print(i+1, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти все темы кажутся удачными и интерпретируемыми.\n",
    "К неудачным можно отнести только темы 1, 13, 15 и 20. Также некоторые темы пересекаются.\n",
    "\n",
    "1: ?философия и литература\n",
    "2: ООП\n",
    "3: разработка игр\n",
    "4: веб-разработка\n",
    "5: гаджеты\n",
    "6: инфраструктура данных\n",
    "7: IT-бизнес\n",
    "8: снова гаджеты\n",
    "9: файлы, скрипты, репозитории\n",
    "10: когнитивные исследования\n",
    "11: веб\n",
    "12: космос\n",
    "13: какие-то языки программирования\n",
    "14: управление IT-командой\n",
    "15: снова какие-то языки программирования\n",
    "16: технологии производства\n",
    "17: доклады и конференции\n",
    "18: сеть\n",
    "19: система\n",
    "20: ?frontend, веб"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA с 20 темами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaMulticore(corpus, num_topics=20, id2word=dictionary, passes=10)\n",
    "topics = lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['человек', 'компания', 'год', 'делать', 'проект', 'говорить', 'деньга', 'сотрудник', 'хотеть']\n",
      "2 ['lt', 'name', 'string', 'the', 'i', 'this', 'amp', 'файл', 'type']\n",
      "3 ['запрос', 'сервер', 'система', 'диск', 'пользователь', 'проблема', 'тест', 'запись']\n",
      "4 ['код', 'класс', 'объект', 'метод', 'файл', 'элемент', 'тип', 'функция', 'приложение', 'пример']\n",
      "5 ['человек', 'год', 'компания', 'робот', 'система', 'машина', 'технология', 'автомобиль', 'ия', 'компьютер']\n",
      "6 ['звук', 'человек', 'глаз', 'учёный', 'движение', 'тело', 'пациент', 'случай', 'система']\n",
      "7 ['проект', 'задача', 'разработка', 'разработчик', 'сайт', 'делать', 'продукт', 'игра', 'команда', 'язык']\n",
      "8 ['человек', 'год', 'ребёнок', 'ваш', 'исследование', 'мозг', 'курс', 'результат']\n",
      "9 ['точка', 'объект', 'значение', 'алгоритм', 'вселенная', 'тип', 'число', 'результат', 'количество', 'координата']\n",
      "10 ['игра', 'игрок', 'игровой', 'играть', 'процессор', 'сервер', 'система', 'уровень', 'видеокарта']\n",
      "11 ['компания', 'пользователь', 'сервис', 'клиент', 'система', 'информация', 'сайт', 'год', 'решение', 'рынок']\n",
      "12 ['год', 'система', 'земля', 'спутник', 'проект', 'аппарат', 'звезда', 'станция', 'энергия']\n",
      "13 ['функция', 'код', 'значение', 'память', 'программа', 'число', 'тип', 'массив', 'результат']\n",
      "14 ['делать', 'написать', 'писать', 'язык', 'слово', 'человек', 'доклад', 'код']\n",
      "15 ['запись', 'транзакция', 'элемент', 'список', 'запрос', 'модель', 'блок']\n",
      "16 ['приложение', 'файл', 'проект', 'устройство', 'команда', 'система', 'версия', 'необходимый', 'пакет', 'помощь']\n",
      "17 ['сеть', 'система', 'модель', 'сигнал', 'изображение', 'задача', 'результат', 'решение', 'устройство', 'являться']\n",
      "18 ['сервер', 'клиент', 'настройка', 'пользователь', 'адрес', 'сеть', 'домен', 'сайт', 'система', 'ваш']\n",
      "19 ['пользователь', 'приложение', 'устройство', 'система', 'пароль', 'уязвимость', 'безопасность', 'атака', 'информация', 'android']\n",
      "20 ['устройство', 'камера', 'модель', 'смартфон', 'компания', 'цена', 'год', 'экран', 'телефон']\n"
     ]
    }
   ],
   "source": [
    "for i, topic in topics:\n",
    "    print(i+1, re.findall(r'(?<=\")[A-Za-zА-Яа-яЁё]+(?=\")', topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в LDA почти все темы получились грязными (смесь нескольких тем) либо совершенно неинтерпретируемыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
